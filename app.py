import streamlit as st
import requests
import pandas as pd
import time
import random
from bs4 import BeautifulSoup
import re
from docx import Document
from docx.shared import Inches
from docx.enum.text import WD_PARAGRAPH_ALIGNMENT
import io
import json
from typing import List, Dict, Tuple, Optional
import logging
from dataclasses import dataclass
# Imports IA - syntaxe compatible avec les derniÃ¨res versions
try:
    from openai import OpenAI  # Pour OpenAI v1.0+
except ImportError:
    import openai  # Fallback pour versions antÃ©rieures
import anthropic
import google.generativeai as genai
import trafilatura
from urllib.parse import urlparse
import base64

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class CompetitorData:
    """Structure pour stocker les donnÃ©es d'un concurrent"""
    url: str
    title: str
    meta_description: str
    headings: Dict[str, List[str]]
    position: int
    raw_html: str
    extraction_success: bool
    error_message: str = ""
    relevance_score: float = 0.0
    selected: bool = False

@dataclass
class SEOBrief:
    """Structure pour le brief SEO final"""
    target_keyword: str
    optimized_title: str
    optimized_meta_description: str
    headings_structure: str
    country: str
    language: str
    competitors_analyzed: List[str]

class DataForSEOConfig:
    """Configuration pour les pays et langues supportÃ©s par DataForSEO"""
    
    SUPPORTED_MARKETS = {
        "ğŸ‡«ğŸ‡· France": {
            "location_code": 2250,
            "country_code": "FR",
            "languages": {"FranÃ§ais": "fr"},
            "google_domain": "google.fr"
        },
        "ğŸ‡ºğŸ‡¸ Ã‰tats-Unis": {
            "location_code": 2840,
            "country_code": "US",
            "languages": {"English": "en"},
            "google_domain": "google.com"
        },
        "ğŸ‡¬ğŸ‡§ Royaume-Uni": {
            "location_code": 2826,
            "country_code": "GB",
            "languages": {"English": "en"},
            "google_domain": "google.co.uk"
        },
        "ğŸ‡©ğŸ‡ª Allemagne": {
            "location_code": 2276,
            "country_code": "DE", 
            "languages": {"Deutsch": "de", "English": "en"},
            "google_domain": "google.de"
        },
        "ğŸ‡ªğŸ‡¸ Espagne": {
            "location_code": 2724,
            "country_code": "ES",
            "languages": {"EspaÃ±ol": "es", "English": "en"},
            "google_domain": "google.es"
        },
        "ğŸ‡®ğŸ‡¹ Italie": {
            "location_code": 2380,
            "country_code": "IT",
            "languages": {"Italiano": "it", "English": "en"},
            "google_domain": "google.it"
        },
        "ğŸ‡§ğŸ‡ª Belgique": {
            "location_code": 2056,
            "country_code": "BE",
            "languages": {"FranÃ§ais": "fr", "Nederlands": "nl"},
            "google_domain": "google.be"
        },
        "ğŸ‡¨ğŸ‡¦ Canada": {
            "location_code": 2124,
            "country_code": "CA",
            "languages": {"English": "en", "FranÃ§ais": "fr"},
            "google_domain": "google.ca"
        }
    }
    
    @classmethod
    def get_market_config(cls, country_name: str, language_name: str) -> Dict:
        """RÃ©cupÃ¨re la configuration pour un pays et une langue donnÃ©s"""
        if country_name not in cls.SUPPORTED_MARKETS:
            raise ValueError(f"Pays non supportÃ©: {country_name}")
        
        market = cls.SUPPORTED_MARKETS[country_name]
        
        if language_name not in market["languages"]:
            raise ValueError(f"Langue non supportÃ©e pour {country_name}: {language_name}")
        
        return {
            "location_code": market["location_code"],
            "language_code": market["languages"][language_name],
            "country_code": market["country_code"],
            "google_domain": market["google_domain"]
        }
    
    @classmethod
    def get_available_languages(cls, country_name: str) -> List[str]:
        """RÃ©cupÃ¨re les langues disponibles pour un pays"""
        if country_name not in cls.SUPPORTED_MARKETS:
            return []
        return list(cls.SUPPORTED_MARKETS[country_name]["languages"].keys())

class DataForSEOAPI:
    """Classe pour interfacer avec DataForSEO SERP API"""
    
    def __init__(self, username: str, password: str):
        self.username = username
        self.password = password
        self.base_url = "https://api.dataforseo.com/v3"
        self.session = requests.Session()
        
        # Configuration de l'authentification
        credentials = f"{username}:{password}"
        encoded_credentials = base64.b64encode(credentials.encode()).decode()
        self.session.headers.update({
            "Authorization": f"Basic {encoded_credentials}",
            "Content-Type": "application/json"
        })
    
    def search_serp_live(self, keyword: str, location_code: int, language_code: str, 
                        num_results: int = 10) -> List[Dict]:
        """Effectue une recherche SERP en temps rÃ©el via DataForSEO"""
        endpoint = f"{self.base_url}/serp/google/organic/live/advanced"
        
        payload = [{
            "keyword": keyword,
            "location_code": location_code,
            "language_code": language_code,
            "device": "desktop",
            "os": "windows",
            "depth": min(num_results, 100),
            "calculate_rectangles": False
        }]
        
        try:
            response = self.session.post(endpoint, json=payload)
            response.raise_for_status()
            data = response.json()
            
            if data.get("status_code") != 20000:
                logger.error(f"DataForSEO API Error: {data.get('status_message')}")
                return []
            
            # Extraction des rÃ©sultats organiques
            results = []
            if data.get("tasks") and data["tasks"][0].get("result"):
                serp_items = data["tasks"][0]["result"][0].get("items", [])
                
                for i, item in enumerate(serp_items, 1):
                    if item.get("type") == "organic" and item.get("url"):
                        results.append({
                            "position": i,
                            "title": item.get("title", ""),
                            "url": item.get("url", ""),
                            "snippet": item.get("description", ""),
                            "meta_description": item.get("description", "")
                        })
                    
                    if len(results) >= num_results:
                        break
            
            return results
            
        except Exception as e:
            logger.error(f"Erreur DataForSEO API: {e}")
            return []

class TrafilaturaExtractor:
    """Classe pour extraire le contenu avec Trafilatura"""
    
    @staticmethod
    def extract_content_and_headings(url: str) -> CompetitorData:
        """Extrait le contenu et la structure Hn avec Trafilatura"""
        try:
            # TÃ©lÃ©chargement avec trafilatura
            downloaded = trafilatura.fetch_url(url)
            
            if not downloaded:
                return CompetitorData(
                    url=url, title="", meta_description="", headings={}, 
                    position=0, raw_html="", extraction_success=False,
                    error_message="Impossible de tÃ©lÃ©charger la page"
                )
            
            # Parse HTML pour extraction manuelle des Ã©lÃ©ments
            soup = BeautifulSoup(downloaded, 'html.parser')
            
            # Extraction du title
            title_tag = soup.find('title')
            title = title_tag.get_text().strip() if title_tag else ""
            
            # Extraction meta description
            meta_desc = TrafilaturaExtractor._extract_meta_description(soup)
            
            # Extraction des headings directement depuis le HTML
            headings = TrafilaturaExtractor._extract_headings_from_html(soup)
            
            return CompetitorData(
                url=url,
                title=title,
                meta_description=meta_desc,
                headings=headings,
                position=0,  # Sera mis Ã  jour aprÃ¨s
                raw_html=downloaded[:1000],  # Limite pour debug
                extraction_success=True,
                error_message=""
            )
            
        except Exception as e:
            logger.error(f"Erreur Trafilatura pour {url}: {e}")
            return CompetitorData(
                url=url, title="", meta_description="", headings={}, 
                position=0, raw_html="", extraction_success=False,
                error_message=str(e)
            )
    
    @staticmethod
    def _extract_meta_description(soup: BeautifulSoup) -> str:
        """Extrait la meta description depuis le HTML"""
        # Meta description standard
        meta_desc = soup.find('meta', attrs={'name': 'description'})
        if meta_desc and meta_desc.get('content'):
            return meta_desc.get('content', '').strip()
        
        # Fallback sur property="og:description"
        og_desc = soup.find('meta', attrs={'property': 'og:description'})
        if og_desc and og_desc.get('content'):
            return og_desc.get('content', '').strip()
        
        return ""
    
    @staticmethod
    def _extract_headings_from_html(soup: BeautifulSoup) -> Dict[str, List[str]]:
        """Extrait les headings directement depuis le HTML"""
        headings = {}
        
        for level in range(1, 7):  # H1 Ã  H6
            tag_name = f'h{level}'
            tags = soup.find_all(tag_name)
            
            if tags:
                heading_texts = []
                for tag in tags:
                    text = tag.get_text().strip()
                    if text and len(text) <= 200:  # Limite raisonnable
                        # Nettoie le texte
                        text = re.sub(r'\s+', ' ', text)
                        heading_texts.append(text)
                
                if heading_texts:
                    headings[f'H{level}'] = heading_texts
        
        return headings

class RelevanceAnalyzer:
    """Analyse la pertinence des concurrents"""
    
    @staticmethod
    def calculate_keyword_presence_score(title: str, target_keyword: str) -> float:
        """Calcule le score de prÃ©sence du mot-clÃ© dans le titre"""
        if not title or not target_keyword:
            return 0.0
        
        title_lower = title.lower()
        keyword_lower = target_keyword.lower()
        
        # Score exact match
        if keyword_lower in title_lower:
            return 1.0
        
        # Score partiel basÃ© sur les mots individuels
        keyword_words = keyword_lower.split()
        title_words = title_lower.split()
        
        matches = sum(1 for word in keyword_words if word in title_words)
        return matches / len(keyword_words) if keyword_words else 0.0
    
    @staticmethod
    def calculate_heading_structure_score(headings: Dict[str, List[str]]) -> float:
        """Ã‰value la qualitÃ© de la structure des headings"""
        score = 0.0
        
        # PrÃ©sence H1 (obligatoire)
        if 'H1' in headings and headings['H1']:
            score += 0.4
        
        # PrÃ©sence H2 (important)
        if 'H2' in headings and len(headings['H2']) >= 2:
            score += 0.3
        
        # DiversitÃ© de la structure
        levels_present = [level for level in ['H1', 'H2', 'H3', 'H4'] if level in headings and headings[level]]
        if len(levels_present) >= 3:
            score += 0.3
        
        return min(score, 1.0)
    
    @classmethod
    def calculate_relevance_score(cls, competitor_data: CompetitorData, target_keyword: str, position: int) -> float:
        """Calcule le score de pertinence global"""
        # Score position (plus c'est haut, mieux c'est)
        position_score = max(0, (11 - position) / 10) if position <= 10 else 0
        
        # Score prÃ©sence mot-clÃ©
        keyword_score = cls.calculate_keyword_presence_score(competitor_data.title, target_keyword)
        
        # Score structure headings
        structure_score = cls.calculate_heading_structure_score(competitor_data.headings)
        
        # Score final pondÃ©rÃ©
        final_score = (position_score * 0.4 + keyword_score * 0.4 + structure_score * 0.2)
        
        return final_score

class AIAnalyzer:
    """Classe pour interfacer avec les diffÃ©rentes APIs d'IA"""
    
    def __init__(self, ai_provider: str, ai_model: str, api_key: str):
        self.ai_provider = ai_provider.lower()
        self.ai_model = ai_model
        self.api_key = api_key
        
        if self.ai_provider == 'openai':
            self.openai_client = OpenAI(api_key=api_key)
        elif self.ai_provider == 'claude':
            self.anthropic_client = anthropic.Anthropic(api_key=api_key)
        elif self.ai_provider == 'gemini':
            genai.configure(api_key=api_key)
    
    @staticmethod
    def get_available_models(provider: str) -> List[Dict[str, str]]:
        """Retourne les modÃ¨les disponibles pour chaque fournisseur"""
        models = {
            'claude': [
                {
                    'model_id': 'claude-3-5-sonnet-20241022',
                    'name': 'Claude 3.5 Sonnet (DerniÃ¨re version)',
                    'description': 'ğŸš€ Le plus rÃ©cent et performant - RecommandÃ©',
                    'best_for': 'Analyses SEO complexes et crÃ©ativitÃ©'
                },
                {
                    'model_id': 'claude-3-opus-20240229',
                    'name': 'Claude 3 Opus',
                    'description': 'ğŸ’ª Le plus puissant pour analyses complexes',
                    'best_for': 'Analyses approfondies et raisonnement complexe'
                },
                {
                    'model_id': 'claude-3-sonnet-20240229',
                    'name': 'Claude 3 Sonnet',
                    'description': 'âš–ï¸ Ã‰quilibrÃ© performance/rapiditÃ©',
                    'best_for': 'Usage gÃ©nÃ©ral Ã©quilibrÃ©'
                }
            ],
            'openai': [
                {
                    'model_id': 'gpt-4o',
                    'name': 'GPT-4o (Omni)',
                    'description': 'ğŸš€ Le plus rÃ©cent et optimisÃ© - RecommandÃ©',
                    'best_for': 'Analyses SEO avancÃ©es avec vision multimodale'
                },
                {
                    'model_id': 'gpt-4-turbo',
                    'name': 'GPT-4 Turbo',
                    'description': 'ğŸ’¨ Version optimisÃ©e pour la vitesse',
                    'best_for': 'Analyses rapides et efficaces'
                },
                {
                    'model_id': 'gpt-4',
                    'name': 'GPT-4',
                    'description': 'ğŸ¯ Version standard puissante',
                    'best_for': 'Analyses dÃ©taillÃ©es et prÃ©cises'
                }
            ],
            'gemini': [
                {
                    'model_id': 'gemini-1.5-pro',
                    'name': 'Gemini 1.5 Pro',
                    'description': 'ğŸš€ Le plus performant - RecommandÃ©',
                    'best_for': 'Analyses SEO complexes avec large contexte'
                },
                {
                    'model_id': 'gemini-1.5-flash',
                    'name': 'Gemini 1.5 Flash',
                    'description': 'âš¡ Plus rapide et efficace',
                    'best_for': 'Analyses rapides avec bon rapport qualitÃ©/vitesse'
                }
            ]
        }
        return models.get(provider.lower(), [])
    
    def analyze_with_custom_prompt(self, prompt: str) -> str:
        """Effectue une analyse avec un prompt personnalisÃ©"""
        try:
            if self.ai_provider == 'openai':
                # Nouvelle syntaxe OpenAI v1.0+
                response = self.openai_client.chat.completions.create(
                    model=self.ai_model,
                    messages=[
                        {"role": "system", "content": "Tu es un expert SEO senior."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.3,
                    max_tokens=1500
                )
                return response.choices[0].message.content
                
            elif self.ai_provider == 'claude':
                # Syntaxe Claude (correcte)
                message = self.anthropic_client.messages.create(
                    model=self.ai_model,
                    max_tokens=1500,
                    temperature=0.3,
                    messages=[
                        {"role": "user", "content": prompt}
                    ]
                )
                return message.content[0].text
                
            elif self.ai_provider == 'gemini':
                # Syntaxe Gemini (correcte)
                model = genai.GenerativeModel(self.ai_model)
                response = model.generate_content(
                    prompt,
                    generation_config=genai.types.GenerationConfig(
                        temperature=0.3,
                        max_output_tokens=1500
                    )
                )
                return response.text
                
        except Exception as e:
            logger.error(f"Erreur API {self.ai_provider} ({self.ai_model}): {e}")
            return f"Erreur lors de l'analyse: {e}"

class PromptTemplates:
    """Templates de prompts pour les diffÃ©rentes analyses"""
    
    @staticmethod
    def get_structure_prompt(keyword: str, competitors_data: List[CompetitorData]) -> str:
        """GÃ©nÃ¨re le prompt pour l'analyse de structure"""
        
        prompt = f"""Tu es un expert SEO.
J'ai collectÃ© plusieurs contenus concurrents (titres, Hn, paragraphes) sur la requÃªte "{keyword}".
Analyse-les en profondeur pour :
1. Identifier les intentions de recherche couvertes et manquantes.
2. Construire une structure Hn complÃ¨te et hiÃ©rarchisÃ©e (H1, H2, H3, H4 si nÃ©cessaire).
3. Optimiser le plan pour rÃ©pondre Ã  toutes les questions des internautes et surpasser les concurrents.
4. La structure doit Ãªtre claire, logique, sans rÃ©pÃ©titions inutiles, et inclure des variantes sÃ©mantiques du mot-clÃ©.

DONNÃ‰ES DES CONCURRENTS:
"""
        
        for i, comp in enumerate(competitors_data, 1):
            if comp.extraction_success:
                prompt += f"""
CONCURRENT {i} (Position {comp.position}):
URL: {comp.url}
TITLE: {comp.title}
STRUCTURE Hn:
"""
                for level, headings in comp.headings.items():
                    for heading in headings:
                        prompt += f"  {level}: {heading}\n"
        
        prompt += """
Donne-moi uniquement :
- Un H1 optimisÃ© (avec le mot-clÃ© principal).
- Les H2/H3/H4 proposÃ©s sous forme d'arborescence claire.

Format de rÃ©ponse attendu:
**H1:** [Ton H1 optimisÃ©]

**H2:** [Premier H2]
* **H3:** [Premier H3]
* **H3:** [DeuxiÃ¨me H3]

**H2:** [DeuxiÃ¨me H2]
* **H3:** [Premier H3]
* **H3:** [DeuxiÃ¨me H3]
  * **H4:** [H4 si nÃ©cessaire]

etc.
"""
        
        return prompt
    
    @staticmethod
    def get_title_prompt(keyword: str, competitors_data: List[CompetitorData]) -> str:
        """GÃ©nÃ¨re le prompt pour l'analyse de title"""
        
        prompt = f"""Tu es un expert SEO.
J'ai scrappÃ© plusieurs titles de concurrents sur la requÃªte "{keyword}".
Analyse-les pour :
1. Identifier leurs forces et faiblesses.
2. CrÃ©er un Title unique, diffÃ©renciant, et optimisÃ© SEO.
3. Respecter une longueur infÃ©rieure Ã  70 caractÃ¨res.
4. Inclure le mot-clÃ© principal sans suroptimisation, avec un ton attractif.

TITLES DES CONCURRENTS:
"""
        
        for i, comp in enumerate(competitors_data, 1):
            if comp.extraction_success and comp.title:
                prompt += f"""
Position {comp.position}: {comp.title}
URL: {comp.url}
"""
        
        prompt += """
Donne-moi uniquement :
- Une proposition de Title optimisÃ©.

Format de rÃ©ponse attendu:
**Title optimisÃ©:** [Ton title ici]
"""
        
        return prompt
    
    @staticmethod
    def get_meta_description_prompt(keyword: str, competitors_data: List[CompetitorData]) -> str:
        """GÃ©nÃ¨re le prompt pour l'analyse de meta description"""
        
        prompt = f"""Tu es un expert SEO.
J'ai scrappÃ© plusieurs meta descriptions de concurrents sur la requÃªte "{keyword}".
Analyse-les pour :
1. Identifier leurs forces et faiblesses.
2. CrÃ©er une Meta Description unique, diffÃ©renciante, et optimisÃ©e SEO.
3. Respecter une longueur entre 140-155 caractÃ¨res.
4. Inclure le mot-clÃ© principal et un appel Ã  l'action attractif.

META DESCRIPTIONS DES CONCURRENTS:
"""
        
        for i, comp in enumerate(competitors_data, 1):
            if comp.extraction_success and comp.meta_description:
                prompt += f"""
Position {comp.position}: {comp.meta_description}
URL: {comp.url}
"""
        
        prompt += """
Donne-moi uniquement :
- Une proposition de Meta Description optimisÃ©e.

Format de rÃ©ponse attendu:
**Meta Description optimisÃ©e:** [Ta meta description ici]
"""
        
        return prompt

class WordGenerator:
    """Classe pour gÃ©nÃ©rer le document Word final"""
    
    @staticmethod
    def create_seo_brief_document(seo_brief: SEOBrief) -> io.BytesIO:
        """GÃ©nÃ¨re le document Word du brief SEO"""
        doc = Document()
        
        # Titre principal
        title = doc.add_heading(f'Brief SEO - {seo_brief.target_keyword}', 0)
        title.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER
        
        # Informations contextuelles
        context_p = doc.add_paragraph(f'MarchÃ©: {seo_brief.country} | Langue: {seo_brief.language}')
        context_p.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER
        
        # Date
        date_p = doc.add_paragraph(f'Date de gÃ©nÃ©ration: {time.strftime("%d/%m/%Y")}')
        date_p.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER
        
        doc.add_page_break()
        
        # Section SEO On-Page
        doc.add_heading('1. Optimisation On-Page', level=1)
        
        # Title
        doc.add_heading('Balise Title', level=2)
        title_p = doc.add_paragraph(seo_brief.optimized_title)
        title_p.style = 'Intense Quote'
        doc.add_paragraph(f'CaractÃ¨res: {len(seo_brief.optimized_title)}')
        
        # Meta Description
        doc.add_heading('Meta Description', level=2)
        meta_p = doc.add_paragraph(seo_brief.optimized_meta_description)
        meta_p.style = 'Intense Quote'
        doc.add_paragraph(f'CaractÃ¨res: {len(seo_brief.optimized_meta_description)}')
        
        # Structure Hn
        doc.add_heading('2. Structure des Headings', level=1)
        doc.add_paragraph(seo_brief.headings_structure)
        
        # Sources
        if seo_brief.competitors_analyzed:
            doc.add_heading('3. Sources AnalysÃ©es', level=1)
            for i, source in enumerate(seo_brief.competitors_analyzed, 1):
                doc.add_paragraph(f'{i}. {source}')
        
        # Sauvegarde en mÃ©moire
        buffer = io.BytesIO()
        doc.save(buffer)
        buffer.seek(0)
        
        return buffer

class SEOBriefGenerator:
    """Classe principale qui orchestre tout le processus"""
    
    def __init__(self):
        self.dataforseo_api = None
        self.extractor = TrafilaturaExtractor()
        self.analyzer = RelevanceAnalyzer()
        self.ai_analyzer = None
        
    def setup_apis(self, dataforseo_username: str, dataforseo_password: str, 
                   ai_provider: str, ai_model: str, ai_api_key: str):
        """Configure les APIs"""
        self.dataforseo_api = DataForSEOAPI(dataforseo_username, dataforseo_password)
        self.ai_analyzer = AIAnalyzer(ai_provider, ai_model, ai_api_key)
    
    def search_and_extract_competitors(self, target_keyword: str, country: str, language: str, 
                                     num_results: int = 10) -> List[CompetitorData]:
        """Recherche et extrait le contenu des concurrents"""
        if not self.dataforseo_api:
            raise ValueError("DataForSEO API non configurÃ©e")
        
        # RÃ©cupÃ©ration de la configuration du marchÃ©
        market_config = DataForSEOConfig.get_market_config(country, language)
        
        # Recherche SERP via DataForSEO
        search_results = self.dataforseo_api.search_serp_live(
            target_keyword, 
            market_config["location_code"],
            market_config["language_code"],
            num_results
        )
        
        # Extraction du contenu avec Trafilatura pour chaque rÃ©sultat
        competitors = []
        for result in search_results:
            competitor_data = self.extractor.extract_content_and_headings(result['url'])
            competitor_data.position = result['position']
            
            # Fallback sur les donnÃ©es DataForSEO si extraction Ã©choue
            if not competitor_data.extraction_success:
                competitor_data.title = result.get('title', '')
                competitor_data.meta_description = result.get('meta_description', '')
            
            # Calcul du score de pertinence
            competitor_data.relevance_score = self.analyzer.calculate_relevance_score(
                competitor_data, target_keyword, result['position']
            )
            
            competitors.append(competitor_data)
        
        return competitors
    
    def auto_select_competitors(self, competitors: List[CompetitorData], max_competitors: int = 5) -> List[CompetitorData]:
        """SÃ©lection automatique des meilleurs concurrents"""
        # Trie par score de pertinence
        sorted_competitors = sorted(competitors, key=lambda x: x.relevance_score, reverse=True)
        
        # SÃ©lectionne les meilleurs
        selected = sorted_competitors[:max_competitors]
        for competitor in selected:
            competitor.selected = True
        
        return selected

# Interface Streamlit
def main():
    st.set_page_config(
        page_title="SEO Brief Generator Pro",
        page_icon="ğŸš€",
        layout="wide"
    )
    
    st.title("ğŸš€ GÃ©nÃ©rateur de Brief SEO Professionnel")
    st.markdown("*Analyse competitive avancÃ©e avec DataForSEO + Trafilatura + IA spÃ©cialisÃ©e*")
    
    # Sidebar pour la configuration
    with st.sidebar:
        st.header("âš™ï¸ Configuration")
        
        # APIs DataForSEO
        st.subheader("ğŸ” DataForSEO API")
        dataforseo_username = st.text_input("Username DataForSEO", type="password")
        dataforseo_password = st.text_input("Password DataForSEO", type="password")
        
        # Configuration IA
        st.subheader("ğŸ¤– Intelligence Artificielle")
        ai_provider = st.selectbox("Fournisseur IA", ["Claude", "OpenAI", "Gemini"])
        
        # RÃ©cupÃ©ration des modÃ¨les disponibles
        available_models = AIAnalyzer.get_available_models(ai_provider.lower())
        
        if available_models:
            model_options = [f"{model['name']}" for model in available_models]
            selected_model_index = st.selectbox(
                f"ModÃ¨le {ai_provider}",
                range(len(model_options)),
                format_func=lambda x: model_options[x]
            )
            
            selected_model_info = available_models[selected_model_index]
            st.info(f"**{selected_model_info['description']}**\n\n*IdÃ©al pour :* {selected_model_info['best_for']}")
            ai_model = selected_model_info['model_id']
        
        ai_api_key = st.text_input(f"ClÃ© API {ai_provider}", type="password")
        
        # Mode de fonctionnement
        st.subheader("âš¡ Mode de fonctionnement")
        auto_mode = st.toggle("Mode automatique", value=False, help="ExÃ©cution automatique de toutes les Ã©tapes 1-5 jusqu'au tÃ©lÃ©chargement")
        
        if not auto_mode:
            max_competitors = st.slider("Nombre max de concurrents Ã  analyser", 3, 10, 5)
    
    # Interface principale
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("ğŸ¯ Configuration de recherche")
        
        # SÃ©lection du marchÃ©
        st.subheader("ğŸŒ MarchÃ© cible")
        countries = list(DataForSEOConfig.SUPPORTED_MARKETS.keys())
        selected_country = st.selectbox("Pays", countries)
        
        # SÃ©lection de la langue
        available_languages = DataForSEOConfig.get_available_languages(selected_country)
        selected_language = st.selectbox("Langue", available_languages)
        
        # Mot-clÃ© cible
        target_keyword = st.text_input("Mot-clÃ© principal", placeholder="Exemple: comment choisir un lit coffre")
        
        num_results = st.slider("Nombre de rÃ©sultats SERP Ã  analyser", 5, 15, 10)
    
    with col2:
        if selected_country and selected_language:
            config = DataForSEOConfig.get_market_config(selected_country, selected_language)
            st.info(f"""**Configuration sÃ©lectionnÃ©e:**
ğŸ“ Pays: {selected_country}
ğŸ—£ï¸ Langue: {selected_language}
ğŸ”— Domaine: {config['google_domain']}""")
    
    # Initialisation du gÃ©nÃ©rateur
    if 'generator' not in st.session_state:
        st.session_state.generator = SEOBriefGenerator()
    
    # Validation des APIs
    apis_configured = all([dataforseo_username, dataforseo_password, ai_api_key])
    
    if not apis_configured:
        st.warning("âš ï¸ Veuillez configurer toutes les APIs dans la barre latÃ©rale")
        return
    
    try:
        st.session_state.generator.setup_apis(
            dataforseo_username, dataforseo_password, 
            ai_provider.lower(), ai_model, ai_api_key
        )
    except Exception as e:
        st.error(f"Erreur configuration API: {e}")
        return
    
    # Initialisation des variables de session
    if 'competitors_data' not in st.session_state:
        st.session_state.competitors_data = []
    if 'search_completed' not in st.session_state:
        st.session_state.search_completed = False
    
    # MODE AUTOMATIQUE - ExÃ©cution complÃ¨te
    if auto_mode:
        if st.button("ğŸš€ GÃ©nÃ©ration automatique complÃ¨te du Brief SEO", type="primary", disabled=not target_keyword):
            
            # Ã‰tape 1: Recherche et extraction
            with st.spinner("ğŸ” Ã‰tape 1/5 - Recherche SERP et extraction du contenu..."):
                try:
                    competitors_data = st.session_state.generator.search_and_extract_competitors(
                        target_keyword, selected_country, selected_language, num_results
                    )
                    
                    if not competitors_data:
                        st.error("âŒ Aucun concurrent trouvÃ©")
                        return
                    
                    st.session_state.competitors_data = competitors_data
                    st.session_state.search_completed = True
                    st.success(f"âœ… Ã‰tape 1/5 - {len(competitors_data)} concurrents trouvÃ©s et analysÃ©s")
                    
                except Exception as e:
                    st.error(f"âŒ Erreur lors de la recherche: {e}")
                    return
            
            # Ã‰tape 2: SÃ©lection automatique
            with st.spinner("ğŸ¤– Ã‰tape 2/5 - SÃ©lection automatique des meilleurs concurrents..."):
                selected_competitors = st.session_state.generator.auto_select_competitors(competitors_data, max_competitors=5)
                st.session_state.selected_competitors = selected_competitors
                st.success(f"âœ… Ã‰tape 2/5 - {len(selected_competitors)} concurrents sÃ©lectionnÃ©s automatiquement")
            
            # Ã‰tape 3: Analyse structure
            with st.spinner("ğŸ—ï¸ Ã‰tape 3/5 - Analyse de la structure Hn..."):
                structure_prompt = PromptTemplates.get_structure_prompt(target_keyword, selected_competitors)
                structure_result = st.session_state.generator.ai_analyzer.analyze_with_custom_prompt(structure_prompt)
                st.session_state.structure_result = structure_result
                st.success("âœ… Ã‰tape 3/5 - Analyse de structure terminÃ©e")
            
            # Ã‰tape 4: Analyse title
            with st.spinner("ğŸ·ï¸ Ã‰tape 4/5 - Analyse du Title..."):
                title_prompt = PromptTemplates.get_title_prompt(target_keyword, selected_competitors)
                title_result = st.session_state.generator.ai_analyzer.analyze_with_custom_prompt(title_prompt)
                st.session_state.title_result = title_result
                st.success("âœ… Ã‰tape 4/5 - Analyse de title terminÃ©e")
            
            # Ã‰tape 5: Analyse meta description
            with st.spinner("ğŸ“ Ã‰tape 5/5 - Analyse de la Meta Description..."):
                meta_prompt = PromptTemplates.get_meta_description_prompt(target_keyword, selected_competitors)
                meta_result = st.session_state.generator.ai_analyzer.analyze_with_custom_prompt(meta_prompt)
                st.session_state.meta_result = meta_result
                st.success("âœ… Ã‰tape 5/5 - Analyse de meta description terminÃ©e")
            
            # GÃ©nÃ©ration automatique du document Word
            with st.spinner("ğŸ“„ GÃ©nÃ©ration du document Word..."):
                try:
                    seo_brief = SEOBrief(
                        target_keyword=target_keyword,
                        optimized_title=st.session_state.title_result,
                        optimized_meta_description=st.session_state.meta_result,
                        headings_structure=st.session_state.structure_result,
                        country=selected_country,
                        language=selected_language,
                        competitors_analyzed=[comp.url for comp in st.session_state.selected_competitors]
                    )
                    
                    word_buffer = WordGenerator.create_seo_brief_document(seo_brief)
                    
                    st.success("ğŸ‰ GÃ©nÃ©ration automatique terminÃ©e avec succÃ¨s !")
                    
                    st.download_button(
                        label="ğŸ“„ TÃ©lÃ©charger le Brief SEO (.docx)",
                        data=word_buffer,
                        file_name=f"brief_seo_{target_keyword.replace(' ', '_')}_{selected_country.split(' ')[1].lower()}.docx",
                        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                    )
                    
                except Exception as e:
                    st.error(f"âŒ Erreur gÃ©nÃ©ration Word: {e}")
    
    else:
        # MODE MANUEL - Ã‰tapes sÃ©parÃ©es
        # Ã‰tape 1: Recherche et extraction des concurrents
        if st.button("ğŸ” 1. Rechercher et extraire les concurrents", type="primary", disabled=not target_keyword):
            
            with st.spinner("ğŸ” Recherche SERP et extraction du contenu..."):
                try:
                    competitors_data = st.session_state.generator.search_and_extract_competitors(
                        target_keyword, selected_country, selected_language, num_results
                    )
                    
                    if not competitors_data:
                        st.error("âŒ Aucun concurrent trouvÃ©")
                        return
                    
                    st.session_state.competitors_data = competitors_data
                    st.session_state.search_completed = True
                    
                    st.success(f"âœ… {len(competitors_data)} concurrents trouvÃ©s et analysÃ©s")
                    
                except Exception as e:
                    st.error(f"âŒ Erreur lors de la recherche: {e}")
                    return
    
    # Affichage des donnÃ©es extraites (debugging)
    if st.session_state.search_completed and st.session_state.competitors_data:
        st.header("ğŸ” DonnÃ©es extraites (Debug)")
        
        competitors_data = st.session_state.competitors_data
        
        # Tableau de debug principal
        debug_data = []
        for comp in competitors_data:
            debug_data.append({
                "Position": comp.position,
                "URL": comp.url,
                "Title": comp.title[:50] + "..." if len(comp.title) > 50 else comp.title,
                "Meta Description": comp.meta_description[:50] + "..." if len(comp.meta_description) > 50 else comp.meta_description,
                "Headings trouvÃ©s": ", ".join(comp.headings.keys()) if comp.headings else "Aucun",
                "Score relevance": f"{comp.relevance_score:.2f}",
                "Extraction OK": "âœ…" if comp.extraction_success else "âŒ",
                "Erreur": comp.error_message[:30] + "..." if comp.error_message and len(comp.error_message) > 30 else comp.error_message
            })
        
        df_debug = pd.DataFrame(debug_data)
        st.dataframe(df_debug, use_container_width=True)
        
        # Nouveau tableau dÃ©taillÃ© des structures Hn
        st.subheader("ğŸ“Š Structure Hn dÃ©taillÃ©e extraite par Trafilatura")
        
        headings_data = []
        for comp in competitors_data:
            if comp.extraction_success and comp.headings:
                for level, headings_list in comp.headings.items():
                    for heading in headings_list:
                        headings_data.append({
                            "Position": comp.position,
                            "URL": comp.url[:40] + "..." if len(comp.url) > 40 else comp.url,
                            "Level": level,
                            "Heading": heading,
                            "CaractÃ¨res": len(heading)
                        })
        
        if headings_data:
            df_headings = pd.DataFrame(headings_data)
            # Tri par position puis par level
            df_headings = df_headings.sort_values(['Position', 'Level'])
            st.dataframe(df_headings, use_container_width=True)
        else:
            st.warning("âš ï¸ Aucune structure Hn extraite par Trafilatura")
        
        # SÃ©lection des concurrents Ã  analyser (MODE MANUEL uniquement)
        if not auto_mode:
            st.subheader("ğŸ“‹ SÃ©lection manuelle des concurrents Ã  analyser")
            
            if 'selected_competitors' not in st.session_state:
                st.session_state.selected_competitors = []
            
            selected_indices = st.multiselect(
                "Choisissez les concurrents Ã  inclure dans l'analyse",
                range(len(competitors_data)),
                format_func=lambda x: f"#{competitors_data[x].position} - {competitors_data[x].title[:60]}... (Score: {competitors_data[x].relevance_score:.2f})",
                default=list(range(min(5, len(competitors_data))))  # SÃ©lectionne les 5 premiers par dÃ©faut
            )
            
            st.session_state.selected_competitors = [competitors_data[i] for i in selected_indices]
        
        # Continuer avec les analyses si des concurrents sont sÃ©lectionnÃ©s (MODE MANUEL)
        if not auto_mode and st.session_state.get('selected_competitors') and len(st.session_state.selected_competitors) > 0:
            st.success(f"âœ… {len(st.session_state.selected_competitors)} concurrents sÃ©lectionnÃ©s pour l'analyse")
            
            # Ã‰tape 2: Analyse de la structure Hn
            st.header("ğŸ—ï¸ 2. Analyse de la structure Hn")
            
            # GÃ©nÃ©ration du prompt pour la structure
            structure_prompt = PromptTemplates.get_structure_prompt(target_keyword, st.session_state.selected_competitors)
            
            # Zone de texte modifiable pour le prompt
            custom_structure_prompt = st.text_area(
                "Prompt pour l'analyse de structure (modifiable)",
                value=structure_prompt,
                height=200,
                key="structure_prompt"
            )
            
            if st.button("ğŸš€ Analyser la structure Hn"):
                with st.spinner("Analyse de la structure en cours..."):
                    structure_result = st.session_state.generator.ai_analyzer.analyze_with_custom_prompt(custom_structure_prompt)
                    st.session_state.structure_result = structure_result
                    st.success("âœ… Analyse de structure terminÃ©e")
            
            # Affichage du rÃ©sultat structure
            if 'structure_result' in st.session_state:
                st.subheader("ğŸ“Š Structure Hn optimisÃ©e")
                st.markdown(st.session_state.structure_result)
            
            # Ã‰tape 3: Analyse du Title
            st.header("ğŸ·ï¸ 3. Analyse du Title")
            
            # GÃ©nÃ©ration du prompt pour le title
            title_prompt = PromptTemplates.get_title_prompt(target_keyword, st.session_state.selected_competitors)
            
            custom_title_prompt = st.text_area(
                "Prompt pour l'analyse du title (modifiable)",
                value=title_prompt,
                height=200,
                key="title_prompt"
            )
            
            if st.button("ğŸš€ Analyser le Title"):
                with st.spinner("Analyse du title en cours..."):
                    title_result = st.session_state.generator.ai_analyzer.analyze_with_custom_prompt(custom_title_prompt)
                    st.session_state.title_result = title_result
                    st.success("âœ… Analyse de title terminÃ©e")
            
            # Affichage du rÃ©sultat title
            if 'title_result' in st.session_state:
                st.subheader("ğŸ·ï¸ Title optimisÃ©")
                st.markdown(st.session_state.title_result)
            
            # Ã‰tape 4: Analyse de la Meta Description
            st.header("ğŸ“ 4. Analyse de la Meta Description")
            
            # GÃ©nÃ©ration du prompt pour la meta description
            meta_prompt = PromptTemplates.get_meta_description_prompt(target_keyword, st.session_state.selected_competitors)
            
            custom_meta_prompt = st.text_area(
                "Prompt pour l'analyse de la meta description (modifiable)",
                value=meta_prompt,
                height=200,
                key="meta_prompt"
            )
            
            if st.button("ğŸš€ Analyser la Meta Description"):
                with st.spinner("Analyse de la meta description en cours..."):
                    meta_result = st.session_state.generator.ai_analyzer.analyze_with_custom_prompt(custom_meta_prompt)
                    st.session_state.meta_result = meta_result
                    st.success("âœ… Analyse de meta description terminÃ©e")
            
            # Affichage du rÃ©sultat meta description
            if 'meta_result' in st.session_state:
                st.subheader("ğŸ“ Meta Description optimisÃ©e")
                st.markdown(st.session_state.meta_result)
            
            # GÃ©nÃ©ration du brief final
            if all(key in st.session_state for key in ['structure_result', 'title_result', 'meta_result']):
                st.header("ğŸ“„ 5. Brief SEO Final")
                
                # AperÃ§u du brief
                col1, col2 = st.columns(2)
                
                with col1:
                    st.subheader("ğŸ·ï¸ Balises SEO")
                    st.write("**Title:**")
                    st.code(st.session_state.title_result)
                    
                    st.write("**Meta Description:**")
                    st.code(st.session_state.meta_result)
                
                with col2:
                    st.subheader("ğŸ“Š Structure Hn")
                    st.markdown(st.session_state.structure_result)
                
                if st.button("ğŸ“„ GÃ©nÃ©rer le document Word"):
                    try:
                        seo_brief = SEOBrief(
                            target_keyword=target_keyword,
                            optimized_title=st.session_state.title_result,
                            optimized_meta_description=st.session_state.meta_result,
                            headings_structure=st.session_state.structure_result,
                            country=selected_country,
                            language=selected_language,
                            competitors_analyzed=[comp.url for comp in st.session_state.selected_competitors]
                        )
                        
                        word_buffer = WordGenerator.create_seo_brief_document(seo_brief)
                        
                        st.download_button(
                            label="ğŸ“„ TÃ©lÃ©charger le Brief SEO (.docx)",
                            data=word_buffer,
                            file_name=f"brief_seo_{target_keyword.replace(' ', '_')}_{selected_country.split(' ')[1].lower()}.docx",
                            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                        )
                        
                        st.success("âœ… Document Word gÃ©nÃ©rÃ©!")
                        
                    except Exception as e:
                        st.error(f"âŒ Erreur gÃ©nÃ©ration Word: {e}")
        
        elif not auto_mode:
            st.warning("âš ï¸ Veuillez sÃ©lectionner au moins un concurrent pour continuer")
    
    # Affichage des rÃ©sultats si mode automatique et analyses terminÃ©es
    if auto_mode and all(key in st.session_state for key in ['structure_result', 'title_result', 'meta_result']):
        st.header("ğŸ“„ Brief SEO GÃ©nÃ©rÃ© Automatiquement")
        
        # AperÃ§u du brief
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ğŸ·ï¸ Balises SEO")
            st.write("**Title:**")
            st.code(st.session_state.title_result)
            
            st.write("**Meta Description:**")
            st.code(st.session_state.meta_result)
        
        with col2:
            st.subheader("ğŸ“Š Structure Hn")
            st.markdown(st.session_state.structure_result)
    
    # Bouton pour reset
    if st.session_state.search_completed:
        if st.button("ğŸ”„ Nouvelle recherche"):
            # Reset de toutes les variables de session
            for key in ['competitors_data', 'search_completed', 'selected_competitors', 'structure_result', 'title_result', 'meta_result']:
                if key in st.session_state:
                    del st.session_state[key]
            st.rerun()

if __name__ == "__main__":
    main()
